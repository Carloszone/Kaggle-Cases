{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# setup\n\nimport os\nimport numpy as np \nimport pandas as pd\nimport random\nimport math\n\nimport warnings\nfrom shutil import copyfile\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing import image\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\nfrom tokenizers import BertWordPieceTokenizer\nfrom transformers import BertTokenizer, TFBertModel, BertConfig\ncopyfile(src = \"../input/shoppee-modles/tokenization.py\", dst = \"../working/tokenization.py\")\nimport tokenization\nimport cuml\nfrom cuml.neighbors import NearestNeighbors\nfrom tqdm import tqdm\nimport gc\nfrom cuml.feature_extraction.text import TfidfVectorizer\nimport cudf, cuml, cupy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Configuration\nBATCH_SIZE = 8\nIMAGE_SIZE = [512, 512]\n# Seed\nSEED = 42\n# Verbosity\nVERBOSE = 1\n# Number of classes\nN_CLASSES = 11014","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RESTRICT TENSORFLOW TO 6GB OF GPU RAM\n# SO THAT WE HAVE 14GB RAM FOR RAPIDS\nLIMIT = 6.0\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(\n            gpus[0],\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        print(e)\nprint('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RESTRICT TENSORFLOW TO 6GB OF GPU RAM\n# SO THAT WE HAVE 14GB RAM FOR RAPIDS\nLIMIT = 6.0\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(\n            gpus[0],\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        print(e)\nprint('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set mode flag\nflag = True\ntest_set = pd.read_csv('../input/shopee-product-matching/test.csv')\nif len(test_set) > 3:\n    flag = False\n\n# Function to get our f1 score\ndef f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1\n\n# Function to read out dataset\ndef load_dataset():\n    if flag:\n        df = pd.read_csv('../input/shopee-product-matching/train.csv')\n        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n        df['orig_matches'] = df['label_group'].map(tmp)\n        df['orig_matches'] = df['orig_matches'].apply(lambda x: ' '.join(x))\n        df['image'] = '../input/shopee-product-matching/train_images/' + df['image']\n        return df\n    else:\n        df = pd.read_csv('../input/shopee-product-matching/test.csv')\n        df['image'] = '../input/shopee-product-matching/test_images/' + df['image']\n        return df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Arcmarginproduct class keras layer\nclass ArcMarginProduct(tf.keras.layers.Layer):\n    '''\n    Implements large margin arc distance.\n\n    Reference:\n        https://arxiv.org/pdf/1801.07698.pdf\n        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n            blob/master/src/modeling/metric_learning.py\n    '''\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def bert_encode(texts, tokenizer, max_len=512):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n            \n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len - len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence)\n        tokens += [0] * pad_len\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n        segment_ids = [0] * max_len\n        \n        all_tokens.append(tokens)\n        all_masks.append(pad_masks)\n        all_segments.append(segment_ids)\n    \n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to get our text title embeddings using a pre-trained bert model\ndef get_text_embeddings(df, max_len = 70):\n    embeds = []\n    module_url = \"../input/shoppee-modles/bert_en_uncased_L-24_H-1024_A-16_2\"\n    bert_layer = hub.KerasLayer(module_url, trainable = True)\n    vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n    do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n    tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n    text = bert_encode(df['title'].values, tokenizer, max_len = max_len)\n    \n    margin = ArcMarginProduct(\n            n_classes = 11014, \n            s = 30, \n            m = 0.5, \n            name='head/arc_margin', \n            dtype='float32'\n            )\n    \n    input_word_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n    label = tf.keras.layers.Input(shape = (), name = 'label')\n\n    _, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    clf_output = sequence_output[:, 0, :]\n    x = margin([clf_output, label])\n    output = tf.keras.layers.Softmax(dtype='float32')(x)\n    model = tf.keras.models.Model(inputs = [input_word_ids, input_mask, segment_ids, label], outputs = [output])\n    \n    model.load_weights('../input/shoppee-modles/Bert_9527-2.h5')\n    model = tf.keras.models.Model(inputs = model.input[0:3], outputs = model.layers[-4].output)\n    chunk = 5000\n    iterator = np.arange(np.ceil(len(df) / chunk))\n    for j in iterator:\n        a = int(j * chunk)\n        b = int((j + 1) * chunk)\n        text_chunk = ((text[0][a:b], text[1][a:b], text[2][a:b]))\n        text_embeddings = model.predict(text_chunk, batch_size = BATCH_SIZE)\n        embeds.append(text_embeddings)\n    del model\n    text_embeddings = np.concatenate(embeds)\n    print(f'Our text embeddings shape is {text_embeddings.shape}')\n    del embeds\n    gc.collect()\n    return text_embeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### Function to get 50 nearest neighbors of each image and apply a distance threshold to maximize cv\ndef get_neighbors(df, embeddings, KNN = 50, image = True):\n    model = NearestNeighbors(n_neighbors = KNN)\n    model.fit(embeddings)\n    distances, indices = model.kneighbors(embeddings)\n    \n    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n    if flag:\n        thresholds = list(np.arange(23, 25, 1))\n        scores = []\n        for threshold in thresholds:\n            predictions = []\n            for k in range(embeddings.shape[0]):\n                idx = np.where(distances[k,] < threshold)[0]\n                ids = indices[k,idx]\n                if (len(idx)>1):\n                    arr = distances[k,np.where(distances[k,]<threshold)[0]][1:]\n                    mean = np.mean(arr)\n                    standard_deviation = np.std(arr)\n                    if(standard_deviation>0):\n                        distance_from_mean = abs(arr - mean)\n                        max_deviations = 2\n                        not_outlier = distance_from_mean < max_deviations * standard_deviation\n                        max_dist = arr[not_outlier][-1]\n                        idx = np.where(distances[k,] <= max_dist)[0]\n                        ids = indices[k,idx]\n                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n                predictions.append(posting_ids)\n            df['pred_matches'] = predictions\n            df['f1'] = f1_score(df['orig_matches'], df['pred_matches'])\n            score = df['f1'].mean()\n            print(f'Our f1 score for threshold {threshold} is {score}')\n            scores.append(score)\n        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n        best_threshold = max_score['thresholds'].values[0]\n        best_score = max_score['scores'].values[0]\n        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n        \n        # Use threshold\n        predictions = []\n        for k in range(embeddings.shape[0]):\n            # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n            idx = np.where(distances[k,] < 19)[0]\n            ids = indices[k,idx]\n            posting_ids = df['posting_id'].iloc[ids].values\n            predictions.append(posting_ids)\n    \n    # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n    else:\n        predictions = []\n        for k in tqdm(range(embeddings.shape[0])):\n            idx = np.where(distances[k,] < 17)[0]\n            ids = indices[k,idx]\n            if (len(idx)>1):\n                    arr = distances[k,np.where(distances[k,]<16.0)[0]][1:]\n                    mean = np.mean(arr)\n                    standard_deviation = np.std(arr)\n                    if(standard_deviation>0):\n                        distance_from_mean = abs(arr - mean)\n                        max_deviations = 2\n                        not_outlier = distance_from_mean < max_deviations * standard_deviation\n                        max_dist = arr[not_outlier][-1]\n                        idx = np.where(distances[k,] <= max_dist)[0]\n                        ids = indices[k,idx]\n            posting_ids = df['posting_id'].iloc[ids].values\n            predictions.append(posting_ids)\n        \n    del model, distances, indices\n    gc.collect()\n    return df, predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = load_dataset()\ndf_cu = cudf.DataFrame(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Computing text embeddings...')\nmodel = TfidfVectorizer(stop_words='english', binary=True, max_features=25000)\ntext_embeddings = model.fit_transform(df_cu.title).toarray()\nprint('text embeddings shape',text_embeddings.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nCHUNK = 1024*4\n\nprint('Finding similar titles...')\nCTS = len(df_cu)//CHUNK\nif len(df_cu)%CHUNK!=0: CTS += 1\nfor j in range( CTS ):\n    \n    a = j*CHUNK\n    b = (j+1)*CHUNK\n    b = min(b,len(df_cu))\n    print('chunk',a,'to',b)\n    \n    # COSINE SIMILARITY DISTANCE\n    # cts = np.dot( text_embeddings, text_embeddings[a:b].T).T\n    cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n    \n    for k in range(b-a):\n        # IDX = np.where(cts[k,]>0.7)[0]\n        IDX = cupy.where(cts[k,]>0.75)[0]\n        o = df_cu.iloc[cupy.asnumpy(IDX)].posting_id.to_pandas().values\n        preds.append(o)\n        \ndel model, text_embeddings\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine_predictions(row):\n    x = np.concatenate([row['text_prediction'], row['text_prediction_2']])\n    return ' '.join( np.unique(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_embeddings = get_text_embeddings(df)\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df, text_predictions = get_neighbors(df, text_embeddings, KNN = min(50, len(df)), image = False)\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['text_prediction'] = preds\ndf['text_prediction_2'] = text_predictions\ndf['matches'] = df.apply(combine_predictions, axis = 1)\nif flag:\n    df[['posting_id', 'orig_matches', 'matches']].to_csv('submission.csv', index = False)\n    df['f1'] = f1_score(df['orig_matches'], df['matches'])\n    print(\"the f1 score is\",df['f1'].mean())\nelse:\n    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}