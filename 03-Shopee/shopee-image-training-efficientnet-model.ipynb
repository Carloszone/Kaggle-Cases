{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet\nimport re\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport efficientnet.tfkeras as efn\nimport tensorflow.keras.applications.efficientnet as eff\nfrom sklearn import metrics\nimport gc\n\nfrom tensorflow.keras import backend as K\nimport tensorflow_addons as tfa\nfrom tqdm.notebook import tqdm\nfrom kaggle_datasets import KaggleDatasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Data access\nGCS_PATH = KaggleDatasets().get_gcs_path('shopee-tfrecords')\n\n# Configuration\nEPOCHS = 30\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [512, 512]\n# Seed\nSEED = 9527\n# Learning rate\nLR = 0.0005\n# Verbosity\nVERBOSE = 2\n# Number of classes\nN_CLASSES = 11014\n# Number of folds\nFOLDS = 5\n\n# Training filenames directory\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/*.tfrec')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to get our f1 score\ndef f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1\n\n# Function to seed everything\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n    \ndef arcface_format(posting_id, image, label_group, matches):\n    return posting_id, {'inp1': image, 'inp2': label_group}, label_group, matches\n\n# Data augmentation function\ndef data_augment(posting_id, image, label_group, matches):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_hue(image, 0.01)\n    image = tf.image.random_saturation(image, 0.70, 1.30)\n    image = tf.image.random_contrast(image, 0.80, 1.20)\n    image = tf.image.random_brightness(image, 0.10)\n    return posting_id, image, label_group, matches\n\n# Function to decode our images\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n# This function parse our images and also get the target variable\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"posting_id\": tf.io.FixedLenFeature([], tf.string),\n        \"image_phash\": tf.io.FixedLenFeature([], tf.string),\n        \"title\": tf.io.FixedLenFeature([], tf.string),\n        \"label_group\": tf.io.FixedLenFeature([], tf.int64),\n        \"matches\": tf.io.FixedLenFeature([], tf.string)\n    }\n\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    posting_id = example['posting_id']\n    image = decode_image(example['image'])\n#     label_group = tf.one_hot(tf.cast(example['label_group'], tf.int32), depth = N_CLASSES)\n    label_group = tf.cast(example['label_group'], tf.int32)\n    matches = example['matches']\n    return posting_id, image, label_group, matches\n\n# This function loads TF Records and parse them into tensors\ndef load_dataset(filenames, ordered = False):\n    \n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False \n        \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls = AUTO) \n    return dataset\n\n# This function is to get our training tensors\ndef get_training_dataset(filenames, ordered = False):\n    dataset = load_dataset(filenames, ordered = ordered)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# This function is to get our validation tensors\ndef get_validation_dataset(filenames, ordered = True):\n    dataset = load_dataset(filenames, ordered = ordered)\n    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) \n    return dataset\n\n# Function to count how many photos we have in\ndef count_data_items(filenames):\n    # The number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nprint(f'Dataset: {NUM_TRAINING_IMAGES} training images')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function for a custom learning rate scheduler with warmup and decay\ndef get_lr_callback():\n    lr_start   = 0.000001\n    lr_max     = 0.000005 * BATCH_SIZE\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start   \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max    \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min    \n        return lr\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n    return lr_callback\n\n# Arcmarginproduct class keras layer\nclass ArcMarginProduct(tf.keras.layers.Layer):\n    '''\n    Implements large margin arc distance.\n\n    Reference:\n        https://arxiv.org/pdf/1801.07698.pdf\n        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n            blob/master/src/modeling/metric_learning.py\n    '''\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output\n\n\n# Function to create our EfficientNetB3 model\ndef get_model(mode):\n\n    with strategy.scope():\n\n        margin = ArcMarginProduct(\n            n_classes = N_CLASSES, \n            s = 30, \n            m = 0.5, \n            name='head/arc_margin', \n            dtype='float32'\n            )\n\n        inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n        label = tf.keras.layers.Input(shape = (), name = 'inp2')\n        print(f'load EfficientNetB{mode}')\n        if mode == 0:\n            x = efn.EfficientNetB0(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 1:\n            x = efn.EfficientNetB1(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 2:\n            x = efn.EfficientNetB2(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 3:\n            x = efn.EfficientNetB3(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 4:\n            x = efn.EfficientNetB4(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 5:\n            x = efn.EfficientNetB5(weights = 'imagenet', include_top = False)(inp)\n        elif mode == 6:\n            x = efn.EfficientNetB6(weights = 'imagenet', include_top = False)(inp)\n        else:\n            x = efn.EfficientNetB7(weights = 'imagenet', include_top = False)(inp)\n        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n        x = margin([x, label])\n        \n        output = tf.keras.layers.Softmax(dtype='float32')(x)\n\n        model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n        model.load_weights('../input/shoppee-modles/EfficientNetB5_512_9527.h5')\n        opt = tf.keras.optimizers.Adam(learning_rate = LR)\n\n        model.compile(\n            optimizer = opt,\n            loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n            metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n            ) \n        \n        return model\n\ndef train_and_evaluate():\n\n    # Seed everything\n    seed_everything(SEED)\n    \n    print('\\n')\n    print('-'*50)\n    train_dataset = get_training_dataset(train_set, ordered = False)\n    train_dataset = train_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n    val_dataset = get_validation_dataset(val_set, ordered = True)\n    val_dataset = val_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n    STEPS_PER_EPOCH = count_data_items(train_set) // BATCH_SIZE\n    K.clear_session()\n    model = get_model(mode)\n    # Model checkpoint\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'EfficientNetB3_{IMAGE_SIZE[0]}_{SEED}_{mode}.h5', \n                                                    monitor = 'val_loss', \n                                                    verbose = VERBOSE, \n                                                    save_best_only = True,\n                                                    save_weights_only = True, \n                                                    mode = 'min')\n\n    history = model.fit(train_dataset,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        epochs = EPOCHS,\n                        callbacks = [checkpoint, get_lr_callback()], \n                        validation_data = val_dataset,\n                        verbose = VERBOSE)\n    gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# modes = range(8)\n# for mode in modes:\n#    print('now the mode is',mode)\n#    train_set = tf.io.gfile.glob(GCS_PATH + '/train'+str(SEED)+'*.tfrec')\n#    val_set = tf.io.gfile.glob(GCS_PATH + '/val'+str(SEED)+'*.tfrec')\n#    train_and_evaluate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_and_evaluate():\n\n    # Seed everything\n    seed_everything(SEED)\n    \n    print('\\n')\n    print('-'*50)\n    train_dataset = get_training_dataset(train_set, ordered = False)\n    train_dataset = train_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n    val_dataset = get_validation_dataset(val_set, ordered = True)\n    val_dataset = val_dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n    STEPS_PER_EPOCH = count_data_items(train_set) // BATCH_SIZE\n    K.clear_session()\n    model = get_model(mode)\n    # Model checkpoint\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(f'EfficientNetB{mode}_{IMAGE_SIZE[0]}_{SEED}.h5', \n                                                    monitor = 'val_loss', \n                                                    verbose = VERBOSE, \n                                                    save_best_only = True,\n                                                    save_weights_only = True, \n                                                    mode = 'min')\n\n    history = model.fit(train_dataset,\n                        steps_per_epoch = STEPS_PER_EPOCH,\n                        epochs = EPOCHS,\n                        callbacks = [checkpoint, get_lr_callback()],\n                        validation_data = val_dataset,\n                        verbose = VERBOSE)\n    gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mode = 5\nprint('now the mode is',mode)\ntrain_set = tf.io.gfile.glob(GCS_PATH + '/*'+str(SEED)+'*.tfrec')\nval_set = tf.io.gfile.glob(GCS_PATH + '/*'+str(SEED)+'*.tfrec')\ntrain_and_evaluate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}