{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# setup\n!pip install ../input/shoppee-modles/Keras_Applications-1.0.8-py3-none-any.whl\n!pip install ../input/shoppee-modles/efficientnet-1.1.0-py3-none-any.whl\n\nimport os\nimport numpy as np \nimport pandas as pd\nimport random\nimport math\n\nimport warnings\nfrom shutil import copyfile\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing import image\nimport tensorflow_hub as hub\nimport tensorflow_datasets as tfds\nimport tensorflow.keras.applications as tfka\nfrom tokenizers import BertWordPieceTokenizer\nfrom transformers import BertTokenizer, TFBertModel, BertConfig\ncopyfile(src = \"../input/shoppee-modles/tokenization.py\", dst = \"../working/tokenization.py\")\nimport tokenization\nimport efficientnet.tfkeras as efn\nimport cuml\nfrom cuml.neighbors import NearestNeighbors\nfrom tqdm import tqdm\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set mode flag\nflag = True\ntest_set = pd.read_csv('../input/shopee-product-matching/test.csv')\nif len(test_set) > 3:\n    flag = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Configuration\nBATCH_SIZE = 8\nIMAGE_SIZE = [512, 512]\n# Seed\nSEED = 9627\n# Verbosity\nVERBOSE = 1\n# Number of classes\nN_CLASSES = 11014","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RESTRICT TENSORFLOW TO 6GB OF GPU RAM\n# SO THAT WE HAVE 14GB RAM FOR RAPIDS\nLIMIT = 6.0\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_virtual_device_configuration(\n            gpus[0],\n            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024*LIMIT)])\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        #print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        print(e)\nprint('We will restrict TensorFlow to max %iGB GPU RAM'%LIMIT)\nprint('then RAPIDS can use %iGB GPU RAM'%(16-LIMIT))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to get our f1 score\ndef f1_score(y_true, y_pred):\n    y_true = y_true.apply(lambda x: set(x.split()))\n    y_pred = y_pred.apply(lambda x: set(x.split()))\n    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n    len_y_pred = y_pred.apply(lambda x: len(x)).values\n    len_y_true = y_true.apply(lambda x: len(x)).values\n    f1 = 2 * intersection / (len_y_pred + len_y_true)\n    return f1\n\n# Function to get the embeddings of our images with the fine-tuned model\ndef get_image_embeddings(image_paths):\n    embeds = []\n    \n    margin = ArcMarginProduct(\n            n_classes = N_CLASSES, \n            s = 30, \n            m = 0.5, \n            name='head/arc_margin', \n            dtype='float32'\n            )\n    inp = tf.keras.layers.Input(shape = (*IMAGE_SIZE, 3), name = 'inp1')\n    label = tf.keras.layers.Input(shape = (), name = 'inp2')\n    x = efn.EfficientNetB5(weights = None, include_top = False)(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = margin([x, label])\n        \n    output = tf.keras.layers.Softmax(dtype='float32')(x)\n    model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n    model.load_weights('../input/shoppee-modles/EfficientNetB5_512_9527.h5')\n    model = tf.keras.models.Model(inputs = model.input[0], outputs = model.layers[-4].output)\n    chunk = 5000\n    iterator = np.arange(np.ceil(len(df) / chunk))\n    for j in iterator:\n        a = int(j * chunk)\n        b = int((j + 1) * chunk)\n        image_dataset = get_dataset(image_paths[a:b])\n        image_embeddings = model.predict(image_dataset)\n        embeds.append(image_embeddings)\n        \n    del model\n    image_embeddings = np.concatenate(embeds)\n    print(f'Our image embeddings shape is {image_embeddings.shape}')\n    del embeds\n    gc.collect()\n    return image_embeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to read out dataset\ndef load_dataset():\n    if flag:\n        df = pd.read_csv('../input/shopee-product-matching/train.csv')\n        tmp = df.groupby(['label_group'])['posting_id'].unique().to_dict()\n        df['matches'] = df['label_group'].map(tmp)\n        df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n        image_path = '../input/shopee-product-matching/train_images/' + df['image']\n        return df, image_path\n    else:\n        df = pd.read_csv('../input/shopee-product-matching/test.csv')\n        image_path = '../input/shopee-product-matching/test_images/' + df['image']\n        return df, image_path\n\n\n# Function to decode our images\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n# Function to read our test image and return image\ndef read_image(image):\n    image = tf.io.read_file(image)\n    image = decode_image(image)\n    return image\n\n# Function to get our dataset that read images\ndef get_dataset(image):\n    dataset = tf.data.Dataset.from_tensor_slices(image)\n    dataset = dataset.map(read_image, num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Arcmarginproduct class keras layer\nclass ArcMarginProduct(tf.keras.layers.Layer):\n    '''\n    Implements large margin arc distance.\n\n    Reference:\n        https://arxiv.org/pdf/1801.07698.pdf\n        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n            blob/master/src/modeling/metric_learning.py\n    '''\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n        \n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n    \n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to get 50 nearest neighbors of each image and apply a distance threshold to maximize cv\ndef get_image_neighbors(df, embeddings, KNN = 50):\n    model = NearestNeighbors(n_neighbors = KNN)\n    model.fit(embeddings)\n    distances, indices = model.kneighbors(embeddings)\n    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n    if flag:\n        scores = []\n        thresholds = list(np.arange(3,5,0.5))\n        for threshold in thresholds:\n            predictions = []\n            for k in range(embeddings.shape[0]):\n                idx = np.where(distances[k,] < threshold)[0]\n                ids = indices[k,idx]\n                posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n                predictions.append(posting_ids)\n            df['pred_matches'] = predictions\n            df['f1'] = f1_score(df['matches'], df['pred_matches'])\n            score = df['f1'].mean()\n            print(f'Our f1 score for threshold {threshold} is {score}')\n            scores.append(score)\n        thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n        max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n        best_threshold = max_score['thresholds'].values[0]\n        best_score = max_score['scores'].values[0]\n        print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n        \n        # Use threshold\n        predictions = []\n        for k in range(embeddings.shape[0]):\n            # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n            idx = np.where(distances[k,] < best_threshold)[0]\n            ids = indices[k,idx]\n            posting_ids = df['posting_id'].iloc[ids].values\n            predictions.append(posting_ids)\n    else:\n        predictions = []\n        for k in tqdm(range(embeddings.shape[0])):\n            ids = np.array([])\n            idx = np.where(distances[k,] < 3.9)[0]\n            ids = indices[k,idx]\n            posting_ids = df['posting_id'].iloc[ids].values\n            predictions.append(posting_ids)\n\n    del model, distances, indices\n    gc.collect()\n    return df, predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df,image_path = load_dataset()\nembeddings = get_image_embeddings(image_path)\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df,prediction = get_image_neighbors(df, embeddings, KNN = min(50, len(df)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['image_prediction'] = prediction\ndf['matches'] = df['image_prediction'].apply(lambda x: ' '.join(np.unique(x)))\ndf[['posting_id', 'matches']].to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}